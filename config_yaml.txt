# Servicing Intelligence Configuration

# Data paths
data:
  raw_path: "data_raw.csv"
  processed_path: "data_processed.csv"
  train_split: 0.8
  validation_split: 0.1
  test_split: 0.1

# Preprocessing settings
preprocessing:
  lowercase: true
  remove_punctuation: true
  remove_numbers: false
  mask_pii: true
  min_token_length: 2
  max_text_length: 512
  language: "en"

# Feature engineering
features:
  use_tfidf: true
  use_word2vec: true
  use_bert_embeddings: true
  tfidf_max_features: 5000
  tfidf_ngram_range: [1, 2]
  word2vec_size: 100
  word2vec_window: 5
  word2vec_min_count: 2

# Classifier settings
classifier:
  model_name: "distilbert-base-uncased"  # Options: bert-base-uncased, distilbert-base-uncased
  num_labels: 5
  max_length: 128
  batch_size: 16
  learning_rate: 2.0e-5
  weight_decay: 0.01
  epochs: 3
  warmup_steps: 500
  gradient_accumulation_steps: 1
  save_dir: "models/classifier"
  use_pyspark: false

# Summarizer settings
summarizer:
  model_name: "t5-small"  # Options: t5-small, t5-base, facebook/bart-base
  max_source_length: 512
  max_target_length: 128
  min_target_length: 30
  batch_size: 8
  learning_rate: 3.0e-5
  weight_decay: 0.01
  epochs: 3
  beam_size: 4
  length_penalty: 2.0
  save_dir: "models/summarizer"

# Evaluation settings
evaluation:
  batch_size: 32
  save_confusion_matrix: true
  save_roc_curve: true
  output_dir: "evaluation_results"

# API settings
api:
  host: "0.0.0.0"
  port: 8000
  reload: true
  log_level: "info"

# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "servicing_intelligence.log"

# Categories for classification
categories:
  - "technical_issue"
  - "billing"
  - "account"
  - "feedback"
  - "other"

# PySpark settings (if enabled)
pyspark:
  app_name: "ServicingIntelligence"
  master: "local[*]"
  executor_memory: "4g"
  driver_memory: "2g"
